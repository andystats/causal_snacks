---
title: "Beyond always treat"
subtitle: "How dynamic treatment strategies open a door for real world effectiveness evaluation"
author: 
date: 
output:
  html_document:
    toc: true
    toc_float: true
    collapsed: false
    toc_depth: 2
---

------------------------------------------------------------------------

**Dynamic treatment policies** embody a healthcare model that actively *listens* to patients, continuously monitoring a broad range of factors to guide treatment decisions. In contrast, **static treatment policies** apply predefined rules based on a one-time assessment, assigning patients to *always treat* / *never treat* rules based on demographics, comorbidities, or other identifiers.

Traditional research methodologies, including [randomized controlled trials (RCTs)](https://pmc.ncbi.nlm.nih.gov/articles/PMC8176647/ "If you are unfamiliar with RCTs, this paper from Zabor et al (2020) provides a foundational overview."), have historically followed principles aligned with static treatment policies. In these studies, patients are assessed at a single point in time, assigned to a static treatment regimen, and monitored for outcomes. Similarly, many [real-world evidence (RWE)](https://pmc.ncbi.nlm.nih.gov/articles/PMC8323556/ "If you are unfamiliar with real world evidence (RWE) study trials, this paper by Chodankar (2021) provides a foundational overview.") study designs have been developed to assess static treatments (for example, evaluating the long-term adverse effects of a treatment administered once, without considering subsequent treatment patterns).

As healthcare providers increasingly embrace dynamic treatment strategies, there is a pressing need to evolve research methodologies to accurately assess their outcomes. Traditional study designs often fall short in capturing the complexities of dynamic treatment policies. For instance, while existing research methods can track adverse events in response to a static treatment protocol, they may not effectively evaluate how continuous adjustments in treatment impact patient outcomes over time.

Advances in longitudinal study designs seek to address this gap by developing methodologies capable of studying dynamic treatment policies within real-world settings. In this paper, we will look at the history of reactive treatment studies in clinical research, focusing on recent advancements in RWE/RWD study design. We will examine best practices for feasibility assessment, data collection, and study design, as well as explore advanced causal inference frameworks, such as targeted maximum likelihood estimation (LTMLE), that leverage machine learning to uncover causal relationships in dynamic treatment research.

This paper aims to provide both conceptual foundations and practical guidance for researchers interested in studying dynamic treatment policies. For those new to causal inference, we recommend first reviewing our Crash Course in Causal Methods, which introduces core causal inference concepts essential for understanding the methodologies discussed in this paper.

## Overview

[in progress:

1.  Introduction to static vs. dynamic treatment policies.
2.  Historical context: RCTs and SMART trials.
3.  Longitudinal studies in RWD
4.  Advanced causal methods
5.  Tools + future
6.  Worked example: Permissive anemia.

]

---

# Dynamic Treatment Policies {.tabset}

## Overview

**Treatment policies** are structured guidelines or protocols used by healthcare providers to determine appropriate strategies for managing specific conditions. Grounded in clinical research, these policies provide a framework for decision-making, guiding clinicians in selecting optimal treatment options while balancing factors such as efficacy, safety, and cost-effectiveness.

**Static treatment policies** prescribe fixed medical protocols that apply a uniform approach to patient care, often following an *always treat* or *never treat* rule. These policies do not account for individual patient variability or changing health conditions over time. While static policies can simplify clinical decision-making and promote uniformity in care, their rigidity can lead to *overtreatment* or *undertreatment* when patient needs evolve beyond the initial treatment framework.

Advancements in evidence-based medicine, coupled with the increased availability of electronic health records (EHRs) and real-time patient monitoring, have driven a shift toward more personalized medical care. This shift has led to the emergence of **dynamic treatment policies**, adaptive medical protocols that continuously adjust treatment decisions based on a patient’s evolving condition and response to therapy. Unlike static policies, dynamic treatment policies integrate real-time data, patient feedback, and clinical reassessments to refine treatment strategies over time. By incorporating ongoing evaluations, these policies enhance both the effectiveness and efficiency of care, reducing the risks associated with static approaches.

---

## Example: Lawn Watering Policies

Let's consider a sample study to look at the effects of regular watering on the greenness of lawns in a single town. For this study we will consider three treatment policies:

-   **Static watering policy:** Always water the lawn for thirty minutes, once a day, between 7am and 9am.

-   **Dynamic watering policy #1:** Every morning, review the previous day's weather, and proceed as follows:

    -   If it rained for \>1 hour on the previous day, do not water.

    -   Otherwise, water for thirty minutes, between 7am and 9am.

-   **Dynamic watering policy #2:** Using smart sensors installed in each yard, review the yard's soil moisture content, and proceed as follows:

    -   If the lawn's average soil moisture is above 70%, do not water.

    -   If the lawn's average soil moisture is between 50-70%, water for 15 minutes between 7am and 9am.

    -   If the lawn's average soil moisture is between 25-50%, water for 1 hour between 7am and 9am.

    -   If the lawn's average soil moisture is below 25%, water for 1 hour between 7am and 9am, and for 30 minutes between 7pm and 9pm.

Notice that the **static watering policy** treats all lawns as the same, and every day as the same. It is easy to imagine this *always on* treatment pattern leading to overwatering (not to mention wasted resources).

**Dynamic watering policy #1** uses low-cost methods to assess environmental conditions, creating a responsive watering schedule that avoids overwatering. It does not take into account variations in individual lawns, which might be caused by location or other covariates that could affect water retention.

**Dynamic treatment policy #3** considers each yard's differences and updates information daily to develop a responsive treatment plan. It is the only treatment policy that addresses both underwatering and overwatering. However, this policy requires continuous monitoring and advanced technologies, which may not be available to all participants in the study.

---

# A Brief History of Longitudinal Study Design in Clinical Trials {.tabset}

## Sequential Multiple Assignment Randomized Trials (SMARTs)

In a traditional randomized controlled trials (RCTs), participants are randomly assigned to either a treatment or control group, ensuring that differences in outcomes can be attributed to the intervention rather than external factors. These trials follow a static treatment approach, meaning that once participants are assigned a treatment regimen, it remains unchanged throughout the study. While this design is effective for evaluating single, well-defined interventions, it does not account for how patients’ conditions evolve over time or how they may respond differently to treatment adjustments. As a result, RCTs may not fully capture the complexities of personalized medicine, where treatment decisions are dynamic and continuously tailored to individual patients.

Recognizing the limitations of static treatment models in traditional RCTs, researchers developed **sequential multiple assignment randomized trials (SMARTs)** as a more flexible approach to evaluating adaptive interventions. SMART trials originated in the early 2000s as part of the broader movement toward personalized and precision medicine. The methodology was pioneered by behavioral and mental health researchers seeking to optimize treatment strategies for conditions like depression, ADHD, and substance abuse, where patient responses to initial treatments vary significantly. The goal of SMART designs is to mimic real-world clinical decision-making by allowing for treatment adjustments based on patient progress, rather than adhering to a fixed, one-size-fits-all approach. \*\*[[add a citation]]\*\*

SMART trials differ from traditional RCTs in that participants can be re-randomized at multiple decision points based on how they respond to initial treatments. This allows researchers to evaluate adaptive treatment strategies (ATSs)—structured decision rules that specify how treatments should be modified over time depending on individual patient needs. For example, in a SMART trial for depression treatment, patients who do not respond to an initial medication may be re-randomized to either an increased dose or a switch to a different medication, simulating the kind of decision-making that occurs in clinical practice.

The design of SMART trials builds upon earlier multi-stage decision-making frameworks in biostatistics and engineering, but their application in healthcare research gained traction as precision medicine became a priority. Early applications focused on chronic disease management, psychiatry, and substance use disorders, demonstrating that treatment sequencing and individual tailoring could significantly improve patient outcomes. Over time, SMART methodologies expanded into other fields, including oncology, cardiology, and infectious diseases, where dynamic treatment adaptation is crucial.

The increasing adoption of SMART trials reflects a broader shift toward data-driven, patient-centered research methodologies. By generating evidence on how best to sequence and adjust treatments, SMART trials provide clinicians with actionable insights into optimizing long-term patient care. Their success has also paved the way for more advanced adaptive trial designs, including reinforcement learning approaches and hybrid methods that integrate SMART with real-world evidence and machine learning techniques. These innovations are helping to refine our understanding of dynamic treatment policies, ensuring that research keeps pace with the complexities of modern healthcare.

[ Example: Lawn watering. Policy: Always on: every morning 9am water for 30 minutes Policy Andy: Surrendered to an intelligent system: Rachio listens to the weather service and deactivates if its going to rain. Policy Aimee: Designed so detects soil moisture + listens to the weather DAG: last two are dynamic and responsive to different characteristics. First is static Simulate data There is no possible optimal watering strategy Target outcome: greenness of grass. Design the ultimate strategy Now extend this: City planner is trying to see if the fatter sprinklers are better. He randomly assigns to the fatter sprinklers and designs a study areound the impact of the fatness. he notices Hector has his sprinkler off when it's raining and penalizes Hector: Anyone reactive is kicked out of the program. SMART trials are saying: we kind of get it. We're going to give you some combinations: Water every morning. Louise, water every third morning. But they are still not responsive to the weather -- variations on static assignment. SMART studies have limited ability to incorporate the weeather : the analysis may not even capture the weather and statistics would not be able to capture it. New strategist: if sunny, water. If rainy, don't water. Then we need analytic methods --- recover the rule from all the Trivial: categories of variables: e.g. color of the house. Or nutrients in the soil. Or what is downstream. What variety of grass (cate: conditional average treatment effects - we might identify a rule for different substrata. Different individualized treatment strategies based on actual traits of the yard and conditions.)(Listening should be different for different people)

vcork1 variant (double the dosage) <https://pmc.ncbi.nlm.nih.gov/articles/PMC2787394/>

Then when looking at real longitudinal data, can't recreate the RCT because the intention is that you're looking at more responsive treatment so it wouldn't be possible. ] [ Can set the stage with this and look at Permissive Anemia. So after the walk through, let's take what we learned and set-up a study design ]

## 

# DAGs

greenness of grass time of watering weather that : sunniness / heat

if this is how we draw our dag, we know what variables we need before we pull. If we don't have our DAG, we pull all of this then draw the DAG then we don't have the possibility of unobserved variables in the DAG.

permissive anemia: heart rate, hemoglobin, blood pressure. Look for what pieces could possibly be used in a policy. Intrusion of selection bias if you only pull in people with hemoglobin matched with records. So that's pulling iin people who are hugely sick. Could I predict a patient is missing from their covariates: informative missingness. Else: non-informative missingness and you can dump them.

Analytics: LMTLE You have to be able to quickly make causal contrast : turn a rule into a policy matrix which isn't easy Wrapper to do this: LMTP package (Haodong); Turn the data into a policy matrix that is flipped on based on policy conditions. Intervene on this for your G computation

-   This is where SMART trials were born. (We think of SMART as responsive or reactive; run out of runway anticipating these dynamic treatments)

-   "ex-ante": hard to anticipate all of the meaningful patterns

-   We want something that is reactive that can anticipate all the patterns.

-   Want data who we have longitudinal records, where treatment dynamics have been recorded, with variables you think it reacts To

-   Worked example: intubation / outcome: COVID induced death; decision: when to intubate (not just "if"), what is the strategy?

-   Blood transfusion: Permissive anemia; blood tranf. is hard on your body but you watch your body and develop an optimal strategy

-   Listen to hemoglobin (and what else?) - age ? - DAG is essential

-   Sidebar: DAG is used differently in longitudinal studies. (A is acyclic and you're literally inviting a cycle.) (We don't believe cycles exist because a key feature is the passing of time. Our whole body is feedback loops but they become DAGS with the passage of time (only listens to the past)).

-   Non parametric structural equations (don't have to articulate the form in the same way in these)\

-   But in a problem with this listening nature, that doesn't lend itself to a static treatment, you need to model and know what the triggers are. When and how much?

-   How we articulate the problem drives the analytics: If we only pull the patients with a blood transfusion, we condition on that outcome. But if we pull on patients permissive anemia we generalize further.

-   Who do we condition on?

-   Sidebar: What does it look like if we only condition on an outcome.

-   Background on Dynamic Treatment Regimes (DTR) and Sequential Multiple Assignment Randomized Trials (SMART).

-   Discussion on the use of dynamic treatment policies in healthcare and the role of structured observational data.

## Longitudinal modifiable treatment policies

Longitudinal modifiable treatment policies (LMTPs) are a type of dynamic treatment policy providing adaptive healthcare strategies that evolve over time, based on continuous monitoring and assessment of a patient's health status. These policies leverage data-driven insights from regular health evaluations and patient feedback to adjust treatment plans. They are particularly useful in managing chronic conditions, allowing for proactive interventions and adjustments in response to changes in the patient's condition or emerging medical evidence.

LMTPs can be developed using a variety of causal inference models adapted to address the complexities of longitudinal data. Traditional approaches such as longitudinal propensity score methods, marginal structural models, and instrumental variable analysis have been instrumental tools to estimate causal effects by accounting for confounding variables over time. However, these methods often face limitations in handling complex, high-dimensional data and time-varying confounders. Longitudinal Targeted Maximum Likelihood Estimation (LTMLE) offers a more powerful alternative by integrating machine learning techniques to provide robust and efficient causal estimates. In this paper, we focus on LTMLE due to its ability to adaptively model dynamic treatment regimes and improve the precision of causal inferences in longitudinal studies.

## Proposed Text

Longitudinal modifiable treatment policies (LMTPs) are a sophisticated approach to dynamic treatment that emphasizes continuous adaptation based on patient-specific data. These policies are particularly well-suited for managing chronic conditions, where patient health status can fluctuate over time. By leveraging regular health evaluations and patient feedback, LMTPs enable healthcare providers to make proactive adjustments to treatment plans, ensuring that interventions remain aligned with the patient's evolving needs.

The development of LMTPs is supported by a range of causal inference models that are designed to handle the complexities of longitudinal data. Traditional methods, such as longitudinal propensity score methods and marginal structural models, have been instrumental in estimating causal effects by accounting for confounding variables over time. However, these approaches often face challenges in dealing with high-dimensional data and time-varying confounders.

Longitudinal Targeted Maximum Likelihood Estimation (LTMLE) offers a more powerful alternative by integrating machine learning techniques to provide robust and efficient causal estimates. LTMLE is particularly effective in modeling dynamic treatment regimes, as it can adaptively account for the complex relationships between variables over time. By improving the precision of causal inferences, LTMLE enhances the ability of researchers to develop and evaluate LMTPs.

In practice, LMTPs require a comprehensive understanding of the patient's health trajectory and the factors that influence treatment outcomes. This involves collecting and analyzing longitudinal data, identifying relevant confounders, and specifying appropriate models for causal inference. By doing so, healthcare providers can develop treatment strategies that are both evidence-based and tailored to the individual needs of each patient.

Overall, LMTPs represent a significant advancement in the field of personalized medicine. By embracing these adaptive strategies, healthcare providers can improve the quality of care for patients with chronic conditions, ultimately leading to better health outcomes and more efficient use of healthcare resources.

# **Observational Data in Dynamic Treatment**

## Proposed section goals

-   Limitations of time-based data in observational studies.
-   Overview of potential data sources for dynamic treatment research.
-   Criteria for determining feasibility in time-based research.

## Proposed Text

Observational data plays a crucial role in dynamic treatment research, providing valuable insights into patient trajectories and treatment outcomes. However, the use of time-based data in observational studies presents several challenges that must be addressed to ensure the validity and reliability of research findings.

One of the primary limitations of time-based data is the potential for confounding, where unmeasured variables may influence both the treatment and the outcome. This can lead to biased estimates of causal effects, making it difficult to draw accurate conclusions about the effectiveness of different treatment strategies. To mitigate this issue, researchers must carefully consider the design and analysis of observational studies, employing advanced statistical techniques to account for confounding variables.

Despite these challenges, observational data offers a rich source of information for dynamic treatment research. Electronic health records (EHRs), patient registries, and other forms of structured data provide detailed longitudinal information on patient health status, treatment history, and outcomes. By leveraging these data sources, researchers can gain a deeper understanding of the factors that influence treatment effectiveness and develop more personalized and adaptive treatment strategies.

When determining the feasibility of time-based research, several criteria must be considered. These include the availability and quality of data, the ability to accurately measure relevant variables, and the potential for confounding. Additionally, researchers must assess the generalizability of their findings, considering whether the study population is representative of the broader patient population.

In conclusion, while time-based data in observational studies presents certain challenges, it also offers significant opportunities for advancing dynamic treatment research. By carefully addressing the limitations and leveraging the strengths of observational data, researchers can develop more effective and personalized treatment strategies, ultimately improving patient outcomes and the quality of care.

# **Foundations of Causal Inference**

## Proposed section goals

-   Introduction to causal inference and the construction of Directed Acyclic Graphs (DAGs).
-   Reference to previous team publications for foundational methods.
-   **Existing Text:**
    -   "Counterfactual outcomes refer to the hypothetical scenarios of what would have happened to an individual if they had received a different treatment or intervention than they actually did. In the context of longitudinal analysis, counterfactual outcomes are crucial for understanding the causal effects of time-varying treatments over time."

## Proposed Text

Causal inference is a fundamental aspect of dynamic treatment research, providing the framework for understanding the relationships between treatments, outcomes, and confounders. At its core, causal inference seeks to estimate the effect of a treatment or intervention on an outcome, accounting for the influence of other variables that may affect this relationship.

Directed Acyclic Graphs (DAGs) are a powerful tool for visualizing and analyzing causal relationships. These graphical representations consist of nodes, representing variables, and directed edges, indicating causal influences. The acyclic nature of DAGs ensures that there are no feedback loops, allowing researchers to clearly delineate the causal pathways and dependencies within a system.

In the context of longitudinal studies, DAGs are particularly valuable for modeling the complex temporal relationships between time-varying treatments, outcomes, and confounders. By providing a clear framework for understanding these relationships, DAGs guide the specification of models and the selection of variables for causal inference. This ensures that the causal effects are estimated accurately, enhancing the robustness and validity of the research findings.

Counterfactual outcomes are another key concept in causal inference, representing the hypothetical scenarios of what would have happened to an individual if they had received a different treatment or intervention. By comparing the observed outcomes with these counterfactual scenarios, researchers can estimate the impact of different treatment strategies on patient trajectories. This approach is crucial for identifying the most effective interventions and informing the development of adaptive treatment policies.

In summary, causal inference provides the foundation for dynamic treatment research, enabling researchers to estimate the effects of time-varying treatments and develop more personalized and effective treatment strategies. By leveraging tools such as DAGs and counterfactual outcomes, researchers can gain a deeper understanding of the causal relationships within a system, ultimately improving the quality of care and patient outcomes.

# **Traditional Methods for Analyzing Time-Based Data**

## Proposed section goals

-   Propensity score weighting adapted for DTR.
-   Q functions and Q learning.
-   Other traditional methods for time-based data analysis.
-   **Existing Text:**
    -   "Traditional approaches such as longitudinal propensity score methods, marginal structural models, and instrumental variable analysis have been instrumental tools to estimate causal effects by accounting for confounding variables over time."

## Proposed Text

Traditional methods for analyzing time-based data have been instrumental in advancing our understanding of dynamic treatment regimes. These methods provide the foundation for estimating causal effects in the presence of time-varying confounders, enabling researchers to draw meaningful conclusions about the effectiveness of different treatment strategies.

Propensity score weighting is a widely used technique for addressing confounding in observational studies. By estimating the probability of treatment assignment based on observed covariates, propensity scores allow researchers to balance the treatment groups and reduce bias in causal effect estimates. In the context of dynamic treatment regimes, propensity score weighting can be adapted to account for the sequential nature of treatment decisions, providing a more accurate assessment of treatment effects over time.

Q functions and Q learning are another set of traditional methods used in dynamic treatment research. Q functions represent the expected outcome given a particular treatment decision, while Q learning is an iterative process for estimating these functions. By modeling the relationship between treatment decisions and outcomes, Q learning provides a framework for optimizing treatment strategies and identifying the most effective interventions.

Other traditional methods for time-based data analysis include marginal structural models and instrumental variable analysis. Marginal structural models use inverse probability weighting to account for time-varying confounders, while instrumental variable analysis leverages external variables to estimate causal effects in the presence of unmeasured confounding. These methods have been instrumental in advancing our understanding of dynamic treatment regimes, providing valuable insights into the factors that influence treatment effectiveness.

In conclusion, traditional methods for analyzing time-based data provide a robust framework for estimating causal effects in dynamic treatment research. By leveraging these techniques, researchers can develop more personalized and effective treatment strategies, ultimately improving patient outcomes and the quality of care.

# **Advanced and Novel Causal Methods**

## Proposed section goals

-   Exploration of advanced causal methods for time-based data.
-   Discussion on the integration of these methods into dynamic treatment research.
-   **Existing Text:**
    -   "Longitudinal Targeted Maximum Likelihood Estimation (LTMLE) offers a more powerful alternative by integrating machine learning techniques to provide robust and efficient causal estimates."

## Proposed Text

The field of dynamic treatment research is rapidly evolving, with advanced and novel causal methods offering new opportunities for understanding and optimizing treatment strategies. These methods build on traditional approaches, incorporating machine learning techniques and other innovations to provide more robust and efficient causal estimates.

Longitudinal Targeted Maximum Likelihood Estimation (LTMLE) is a leading example of an advanced causal method that has gained prominence in recent years. By integrating machine learning algorithms with targeted maximum likelihood estimation, LTMLE provides a powerful framework for estimating the effects of time-varying treatments in longitudinal data. This method is particularly effective in settings with complex relationships between variables, such as time-dependent confounding, which can bias traditional estimation methods.

The integration of advanced causal methods into dynamic treatment research offers several advantages. By leveraging machine learning techniques, researchers can capture complex relationships between variables and improve the precision of causal effect estimates. This enables the development of more personalized and adaptive treatment strategies, ultimately leading to better patient outcomes and more efficient use of healthcare resources.

In addition to LTMLE, other advanced causal methods are being explored for their potential to enhance dynamic treatment research. These include Bayesian approaches, which provide a flexible framework for incorporating prior knowledge and uncertainty into causal inference, and reinforcement learning, which offers a data-driven approach to optimizing treatment strategies over time.

In summary, advanced and novel causal methods represent a significant advancement in the field of dynamic treatment research. By embracing these innovative techniques, researchers can gain a deeper understanding of the factors that influence treatment effectiveness and develop more personalized and effective treatment strategies, ultimately improving the quality of care and patient outcomes.

# **Data Handling and Analysis Techniques**

## Proposed section goals

-   Overview of data handling techniques in dynamic treatment research.
-   Discussion on multiple imputation and test-wise deletion as per Witte 2022.
-   Considerations for data quality and integrity in longitudinal studies.

## Proposed Text

Multiple imputation and test-wise deletion are critical techniques for handling missing data in dynamic treatment research, as highlighted by Witte 2022. Multiple imputation involves creating several complete datasets by filling in missing values with plausible data points based on observed data patterns. This approach allows for more robust statistical analyses by accounting for the uncertainty associated with missing data.

Test-wise deletion, on the other hand, involves excluding cases with missing data for specific tests or analyses. While this method can simplify data handling, it may lead to biased results if the missing data is not random. Therefore, careful consideration of the underlying data patterns and potential biases is essential when choosing between these techniques.

Incorporating these data handling methods into dynamic treatment research can enhance the quality and reliability of causal inferences. By addressing the challenges associated with missing data, researchers can ensure that their findings are both valid and generalizable, ultimately improving the effectiveness of dynamic treatment strategies.

# **Comparison of Methods**

## Proposed section goals

-   Pros and cons of traditional versus advanced causal methods.
-   Case studies or examples illustrating the application of different methods.

## Proposed Text

The comparison of traditional and advanced causal methods is a critical aspect of dynamic treatment research, providing insights into the strengths and limitations of different approaches. By understanding the pros and cons of each method, researchers can make informed decisions about the most appropriate techniques for their specific research questions and data contexts.

Traditional causal methods, such as propensity score weighting and marginal structural models, offer several advantages. These methods are well-established and widely used, providing a robust framework for estimating causal effects in the presence of confounding. They are also relatively straightforward to implement, making them accessible to researchers with varying levels of expertise in causal inference.

However, traditional methods also have limitations. They may struggle to handle complex, high-dimensional data and time-varying confounders, which can lead to biased estimates of causal effects. Additionally, these methods often rely on strong assumptions about the relationships between variables, which may not hold in all settings.

Advanced causal methods, such as LTMLE and reinforcement learning, offer a more flexible and powerful alternative. By incorporating machine learning techniques, these methods can capture complex relationships between variables and improve the precision of causal effect estimates. This enables the development of more personalized and adaptive treatment strategies, ultimately leading to better patient outcomes.

Despite their advantages, advanced methods also have challenges. They can be computationally intensive and require a high level of expertise to implement correctly. Additionally, the integration of machine learning techniques introduces new considerations, such as the risk of overfitting and the need for careful model validation.

Case studies and examples can provide valuable insights into the application of different causal methods in dynamic treatment research. By examining real-world scenarios, researchers can gain a deeper understanding of the strengths and limitations of each approach, ultimately guiding the selection of the most appropriate methods for their specific research questions.

In conclusion, the comparison of traditional and advanced causal methods is a critical aspect of dynamic treatment research. By understanding the pros and cons of each approach, researchers can make informed decisions about the most appropriate techniques for their specific research questions and data contexts, ultimately improving the quality of care and patient outcomes.

# **Future Directions in Longitudinal Research**

## Proposed section goals

-   The future of advanced causal methods in longitudinal studies.
-   Introduction to a Shiny app that supports dynamic treatment research.
-   **Existing Text:**
    -   "Dashboard for Dynamic Treatment Policy Evaluation: Describe the R-Shiny-based dashboard that simplifies the application of LTMLE/LMTP. Encourage researchers and clinicians to explore the open-source dashboard for their own datasets."

## Proposed Text

The future of longitudinal research is poised for significant advancements, driven by the development and integration of advanced causal methods. These methods offer new opportunities for understanding and optimizing treatment strategies, ultimately leading to more personalized and effective healthcare delivery.

One of the key areas of focus in future longitudinal research is the continued development and refinement of advanced causal methods, such as LTMLE and reinforcement learning. By leveraging machine learning techniques and other innovations, researchers can gain a deeper understanding of the complex relationships between variables and improve the precision of causal effect estimates. This will enable the development of more personalized and adaptive treatment strategies, ultimately leading to better patient outcomes and more efficient use of healthcare resources.

In addition to methodological advancements, the future of longitudinal research will also be shaped by the development of new tools and technologies that support dynamic treatment research. One such tool is the R-Shiny-based dashboard for Dynamic Treatment Policy Evaluation, which simplifies the application of LTMLE/LMTP and encourages researchers and clinicians to explore the open-source dashboard for their own datasets. This dashboard provides a user-friendly interface for implementing advanced causal methods, making it accessible to a wider audience and facilitating the integration of these techniques into clinical practice.

The future of longitudinal research also holds promise for the development of new data sources and technologies that enhance the collection and analysis of longitudinal data. Advances in wearable technology, remote monitoring, and other forms of digital health data collection will provide researchers with more comprehensive and detailed information on patient health status and treatment outcomes. This will enable the development of more personalized and adaptive treatment strategies, ultimately leading to better patient outcomes and more efficient use of healthcare resources.

In conclusion, the future of longitudinal research is bright, with significant advancements in advanced causal methods and new tools and technologies that support dynamic treatment research. By embracing these innovations, researchers can gain a deeper understanding of the factors that influence treatment effectiveness and develop more personalized and effective treatment strategies, ultimately improving the quality of care and patient outcomes.

# **Conclusion**

Reiterate the importance of moving beyond static treatment comparisons. Emphasize the role of dynamic treatment policies in real-world decision-making. Encourage clinicians to adopt these advanced methods to optimize patient outcomes.

## Proposed Text

The conclusion of this article underscores the critical importance of moving beyond static treatment comparisons and embracing dynamic treatment policies in healthcare. As the field of personalized medicine continues to evolve, dynamic treatment strategies offer a more flexible and responsive approach to patient care, enabling healthcare providers to tailor interventions based on individual patient responses and real-time data.

Dynamic treatment policies play a vital role in real-world decision-making, providing a framework for optimizing treatment strategies and improving patient outcomes. By continuously assessing patient data and making informed decisions about treatment adjustments, healthcare providers can minimize the risks of overtreatment or undertreatment and enhance the overall quality of care.

The adoption of advanced causal methods, such as LTMLE and reinforcement learning, is essential for realizing the full potential of dynamic treatment policies. These methods provide a powerful framework for estimating causal effects and developing personalized treatment strategies, ultimately leading to better patient outcomes and more efficient use of healthcare resources.

Clinicians are encouraged to embrace these advanced methods and integrate them into their practice, leveraging the insights gained from dynamic treatment research to optimize patient care. By doing so, they can contribute to the ongoing advancement of personalized medicine and improve the quality of care for their patients.

In summary, the shift towards dynamic treatment policies represents a significant advancement in the field of healthcare. By embracing these adaptive strategies and leveraging advanced causal methods, healthcare providers can better meet the needs of individual patients, ultimately leading to improved health outcomes and more efficient use of healthcare resources.

# **Reading List**

-   [Dynamic Treatment Regimes](https://pmc.ncbi.nlm.nih.gov/articles/PMC4231831/)
-   [Learning Optimal Dynamic Treatment Regimes](https://pubmed.ncbi.nlm.nih.gov/38879744/)

## Worked Example: Permissive Anemia

To illustrate these concepts, we will present a case study on the treatment of permissive anemia using blood transfusion within a dynamic treatment framework. Using simulated data, we will implement causal inference techniques in R to compare different methodological approaches and assess their effectiveness in recovering the true treatment effect.

[TO ADD: Overview of Permissive Anemia if this is the example we end up using.]
